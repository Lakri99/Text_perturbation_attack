{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37864bitnercondaccbd401f15f74241b78614bb8b344abe",
   "display_name": "Python 3.7.8 64-bit ('ner': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from dataset import data_loaders, get_vocab\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from model import RNN\n",
    "import random\n",
    "import warnings\n",
    "import string\n",
    "import collections\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "TEXT.build_vocab(train_data, \n",
    "                max_size = MAX_VOCAB_SIZE, \n",
    "                vectors = \"glove.6B.100d\", \n",
    "                unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open('vocab.json', 'w') as fp:\n",
    "#     json.dump(TEXT.vocab.stoi, fp)\n",
    "\n",
    "vocab = json.load(open('vocab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "INPUT_DIM = len(vocab)\n",
    "PAD_IDX = vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 100)\n",
       "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT\n",
    "            )\n",
    "path='tut2-model.pt'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "        (train_data, test_data), \n",
    "        batch_size = BATCH_SIZE,\n",
    "        device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_vocab = {}\n",
    "for k,v in vocab.items():\n",
    "    reverse_vocab[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for batch in test_iterator:\n",
    "    text, text_len = batch.text\n",
    "    label = batch.label\n",
    "    i=i+1\n",
    "    if(i>5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    tokenized = [tok.text for tok in nlp(sentence)] \n",
    "    # print(tokenized) #tokenize the sentence \n",
    "    indexed = [vocab.get(t, 0) for t in tokenized]          #convert to integer sequence\n",
    "    length = [len(indexed)]                                    #compute no. of words\n",
    "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
    "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
    "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
    "    prediction = model(tensor, length_tensor)                  #prediction \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I wish I knew what to make of a movie like this. It seems to be divided into two parts -- action sequences and personal dramas ashore. It follows Ashton Kutsher through survival swimmer school, guided by Master Chief Kevin Costner, then to Alaska where a couple of spectacular rescues take place, the last resulting in death.<br /><br />I must say that the scenes on the beach struck me as so stereotypical in so many ways that they should be barnacle encrusted. A typical bar room fight between Navy guys and Coast Guardsmen (\"puddle pirates\"). The experienced old timer Costner who is, as an elderly bar tender tells him, \"married to the Coast Guard.\" The older chief who \"keeps trying to prove to himself that he's still nineteen.\" The neglected ex wife ashore to whom Kostner pays a farewell visit. The seemingly sadistic demands placed on the swimmers by the instructors, all in pursuit of a loftier goal. The gifted young man hobbled by a troubled past.<br /><br />The problem is that we've seen it all before. If it's Kevin Costner here, it's Clint Eastwood or John Wayne or Lou Gosset Jr. or Vigo Mortenson or Robert DeNiro elsewhere. And the climactic scene has elements drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" None of it is fresh and none of the old stereotyped characters and situations are handled with any originality.<br /><br />It works best as a kind of documentary of what goes on in the swimmer's school and what could happen afterward and even that's a little weak because we don't get much in the way of instruction. It's mostly personal conflict, romance, and tension about washing out.<br /><br />It's a shame because the U. S. Coast Guard is rather a noble outfit, its official mission being \"the safety of lives and property at sea.\" In war time it is transferred to the Navy Department and serves in combat roles. In World War II, the Coast Guard even managed to have a Medal of Honor winner in its ranks.<br /><br />But, again, we don't learn much about that. We don't really learn much about anything. The film devolves into a succession of visual displays and not too much else. A disappointment.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1209900751709938"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "predict(model, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ori_op = predict(model, text)\n",
    "    ranking = {}\n",
    "    original_text = text\n",
    "    for word in nlp(text):\n",
    "        if word.text not in string.punctuation and word.text not in stop_words:\n",
    "            new_text = original_text.replace(word.text, '')\n",
    "            new_op = predict(model, new_text)\n",
    "            ranking[word.text] = {\"value\": np.abs(ori_op - new_op).item(), \"pos\": word.pos_}\n",
    "\n",
    "ranking = sorted(ranking.items(), key=lambda x: x[1]['value'], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.13148704171180725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha=0.3\n",
    "orig_text = text\n",
    "i=1\n",
    "for j in range(math.trunc(len(ranking)*alpha)):\n",
    "    synlist = get_synonyms(ranking[j])\n",
    "    if len(synlist)-1 < i:\n",
    "        index = len(synlist)-1\n",
    "    else:\n",
    "        index=i\n",
    "    orig_text = orig_text.replace(ranking[j][0],synlist[index])\n",
    "print(predict(model, orig_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'I bid I eff what to piss of a movie like this. It seems to be part into two parts -- action sequence and personal dramas ashore. It follows Ashton Kutsher through survival natator school, guided by Master Chief Kevin Costner, then to Alaska where a mates of spectacular rescues take place, the last resulting in death.<br /><br />I must say that the scenes on the beach struck me as so stereotypical in so humany ways that they should be barnacle encrusted. A typical bar room fight between Navy guys and Coast Guardsmen (\"puddle pirates\"). The experienced old timer Costner who is, as an elderly bar tender tells him, \"married to the Coast Guard.\" The older chief who \"keeps trying to prove to himself that he\\'s still nineteen.\" The neglected ex wife ashore to whom Kostner pays a farewell visit. The seemingly sadistic dehumands placed on the natators by the instructors, all in pursuit of a loftier goal. The gifted young human hobbled by a troubled past.<br /><br />The problem is that we\\'ve seen it all before. If it\\'s Kevin Costner here, it\\'s Clint Eastwood or John Wayne or Lou Gosset Jr. or Vigo Mortenson or Robert DeNiro elsewhere. And the climactic scene has constituent drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" none of it is fresh and none of the old stereotyped characters and state of affairs are handled with any originality.<br /><br />It work on good as a kind of documentary of what travel on in the natator\\'s school and what could happen afterwarfared and yet that\\'s a little weakly because we don\\'t get much in the way of instruction. It\\'s for the most part personal conflict, rohumance, and tension about washing out.<br /><br />It\\'s a shame because the U. S. Coast Guard is rather a stately outfit, its official mission being \"the base hit of lives and holding at sea.\" In warfare time it is channelize to the Navy Department and wait on in combat part. In World War II, the Coast Guard yet hucope to have a Medal of Honor victor in its ranks.<br /><br />But, again, we don\\'t ascertain much about that. We don\\'t really ascertain much about anything. The motion picture devolves into a sequence of ocular display and not too much else. A letdown.'"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "source": [
    "orig_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.15606075525283813"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "source": [
    "predict(model, orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "t1 = sbert_model.encode(text)\n",
    "t2 = sbert_model.encode(orig_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    if word[1]['pos'] == 'VERB':\n",
    "        pos = wn.VERB\n",
    "    elif word[1]['pos'] == 'ADJ':\n",
    "        pos = wn.ADJ\n",
    "    elif word[1]['pos'] == 'ADV':\n",
    "        pos = wn.ADV\n",
    "    elif word[1]['pos'] == 'NOUN':\n",
    "        pos = wn.NOUN\n",
    "    else:\n",
    "        return [word[0]]\n",
    "    \n",
    "    synonyms = []\n",
    "    for syn in wn.synsets(word[0], pos=pos): \n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name().replace(\"_\", \" \"))\n",
    "    if not synonyms:\n",
    "        synonyms.append(word[0])\n",
    "    return list(set(synonyms)) "
   ]
  }
 ]
}