{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_glove.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8JyQd_FhSOx"
      },
      "source": [
        "#!pip install sentence_transformers\r\n",
        "#import nltk\r\n",
        "#nltk.download('stopwords')\r\n",
        "#nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMSpUVq4grHR"
      },
      "source": [
        "import torch\r\n",
        "from torchtext import data\r\n",
        "from torchtext import datasets\r\n",
        "from dataset import data_loaders, get_vocab\r\n",
        "from nltk.corpus import wordnet as wn\r\n",
        "from sentence_transformers import SentenceTransformer\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import spacy\r\n",
        "from model import RNN\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import string\r\n",
        "import collections\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "import gensim.downloader as api\r\n",
        "import re"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px83si5gg7xM"
      },
      "source": [
        "stop_words = stopwords.words('english')\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7DBan80hkjy",
        "outputId": "b944a11b-fb75-4cf7-998a-6b79490e4322"
      },
      "source": [
        "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\r\n",
        "LABEL = data.LabelField(dtype = torch.float)\r\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:03<00:00, 22.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY2lgwc6hnOO",
        "outputId": "d29748dc-4eda-4a92-9b0d-1faa0ee9a804"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\r\n",
        "TEXT.build_vocab(train_data, \r\n",
        "                max_size = MAX_VOCAB_SIZE, \r\n",
        "                vectors = \"glove.6B.100d\", \r\n",
        "                unk_init = torch.Tensor.normal_)\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [09:47, 1.47MB/s]                           \n",
            "100%|█████████▉| 399129/400000 [00:15<00:00, 25861.91it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfpHyIrAhrf9"
      },
      "source": [
        "import json\r\n",
        "# with open('vocab.json', 'w') as fp:\r\n",
        "#     json.dump(TEXT.vocab.stoi, fp)\r\n",
        "\r\n",
        "vocab = json.load(open('vocab.json'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NdgN_Rahskv"
      },
      "source": [
        "EMBEDDING_DIM = 100\r\n",
        "HIDDEN_DIM = 32\r\n",
        "OUTPUT_DIM = 1\r\n",
        "N_LAYERS = 2\r\n",
        "BIDIRECTIONAL = True\r\n",
        "DROPOUT = 0.2\r\n",
        "N_EPOCHS = 5\r\n",
        "BATCH_SIZE = 1\r\n",
        "INPUT_DIM = len(vocab)\r\n",
        "PAD_IDX = vocab['<pad>']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG2yaVsphuaQ",
        "outputId": "da9ba1cc-ade6-41f8-b85a-2d2bc048ea2d"
      },
      "source": [
        "model = RNN(INPUT_DIM, \r\n",
        "            EMBEDDING_DIM, \r\n",
        "            HIDDEN_DIM, \r\n",
        "            OUTPUT_DIM, \r\n",
        "            N_LAYERS, \r\n",
        "            BIDIRECTIONAL, \r\n",
        "            DROPOUT\r\n",
        "            )\r\n",
        "path='tut2-model.pt'\r\n",
        "model.load_state_dict(torch.load(path))\r\n",
        "model = model.to(device)\r\n",
        "model.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399129/400000 [00:28<00:00, 25861.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(25002, 100)\n",
              "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
              "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (act): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ItA-9ZkhvxS"
      },
      "source": [
        "train_iterator, test_iterator = data.BucketIterator.splits(\r\n",
        "        (train_data, test_data), \r\n",
        "        batch_size = BATCH_SIZE,\r\n",
        "        device = device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUlnFNcfhyEp"
      },
      "source": [
        "reverse_vocab = {}\r\n",
        "for k,v in vocab.items():\r\n",
        "    reverse_vocab[v] = k"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3de04X3hzic"
      },
      "source": [
        "i=0\r\n",
        "for batch in test_iterator:\r\n",
        "    text, text_len = batch.text\r\n",
        "    label = batch.label\r\n",
        "    i=i+1\r\n",
        "    if(i>5):\r\n",
        "        break"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seqdxeoCh0-R"
      },
      "source": [
        "def predict(model, sentence):\r\n",
        "    tokenized = [tok.text for tok in nlp(sentence)] \r\n",
        "    # print(tokenized) #tokenize the sentence \r\n",
        "    indexed = [vocab.get(t, 0) for t in tokenized]          #convert to integer sequence\r\n",
        "    length = [len(indexed)]                                    #compute no. of words\r\n",
        "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\r\n",
        "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\r\n",
        "    length_tensor = torch.LongTensor(length)                   #convert to tensor\r\n",
        "    prediction = model(tensor, length_tensor)                  #prediction \r\n",
        "    return prediction.item()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogCE-4Lmh7Pj"
      },
      "source": [
        "text = \"\"\"I wish I knew what to make of a movie like this. It seems to be divided into two parts -- action sequences and personal dramas ashore. It follows Ashton Kutsher through survival swimmer school, guided by Master Chief Kevin Costner, then to Alaska where a couple of spectacular rescues take place, the last resulting in death.<br /><br />I must say that the scenes on the beach struck me as so stereotypical in so many ways that they should be barnacle encrusted. A typical bar room fight between Navy guys and Coast Guardsmen (\"puddle pirates\"). The experienced old timer Costner who is, as an elderly bar tender tells him, \"married to the Coast Guard.\" The older chief who \"keeps trying to prove to himself that he's still nineteen.\" The neglected ex wife ashore to whom Kostner pays a farewell visit. The seemingly sadistic demands placed on the swimmers by the instructors, all in pursuit of a loftier goal. The gifted young man hobbled by a troubled past.<br /><br />The problem is that we've seen it all before. If it's Kevin Costner here, it's Clint Eastwood or John Wayne or Lou Gosset Jr. or Vigo Mortenson or Robert DeNiro elsewhere. And the climactic scene has elements drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" None of it is fresh and none of the old stereotyped characters and situations are handled with any originality.<br /><br />It works best as a kind of documentary of what goes on in the swimmer's school and what could happen afterward and even that's a little weak because we don't get much in the way of instruction. It's mostly personal conflict, romance, and tension about washing out.<br /><br />It's a shame because the U. S. Coast Guard is rather a noble outfit, its official mission being \"the safety of lives and property at sea.\" In war time it is transferred to the Navy Department and serves in combat roles. In World War II, the Coast Guard even managed to have a Medal of Honor winner in its ranks.<br /><br />But, again, we don't learn much about that. We don't really learn much about anything. The film devolves into a succession of visual displays and not too much else. A disappointment.\"\"\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at0xLTRzh-jb",
        "outputId": "66990ee9-ce86-466b-f815-ed07b6fe5d3d"
      },
      "source": [
        "predict(model, text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12099010497331619"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3D3uFLliAl2"
      },
      "source": [
        "with torch.no_grad():\r\n",
        "    ori_op = predict(model, text)\r\n",
        "    ranking = {}\r\n",
        "    original_text = text\r\n",
        "    for word in nlp(text):\r\n",
        "        if word.text not in string.punctuation and word.text not in stop_words:\r\n",
        "            new_text = original_text.replace(word.text, '')\r\n",
        "            new_op = predict(model, new_text)\r\n",
        "            ranking[word.text] = {\"value\": np.abs(ori_op - new_op).item(), \"pos\": word.pos_}\r\n",
        "\r\n",
        "ranking = sorted(ranking.items(), key=lambda x: x[1]['value'], reverse=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US_tqjldiW3m"
      },
      "source": [
        "def get_synonyms(word):\r\n",
        "    if word[1]['pos'] == 'VERB':\r\n",
        "        pos = wn.VERB\r\n",
        "    elif word[1]['pos'] == 'ADJ':\r\n",
        "        pos = wn.ADJ\r\n",
        "    elif word[1]['pos'] == 'ADV':\r\n",
        "        pos = wn.ADV\r\n",
        "    elif word[1]['pos'] == 'NOUN':\r\n",
        "        pos = wn.NOUN\r\n",
        "    else:\r\n",
        "        return [word[0]]\r\n",
        "    \r\n",
        "    synonyms = []\r\n",
        "    for syn in wn.synsets(word[0], pos=pos): \r\n",
        "        for l in syn.lemmas():\r\n",
        "            synonyms.append(l.name().replace(\"_\", \" \"))\r\n",
        "    if not synonyms:\r\n",
        "        synonyms.append(word[0])\r\n",
        "    return list(set(synonyms))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306eNGy5ibQz",
        "outputId": "f45cc9d9-b9bd-4da1-b9d1-1a4522609ef1"
      },
      "source": [
        "# THIS BLOCK HAS BEEN ADDED WHEN COMPARED TO new.ipynb\r\n",
        "#glove_preTrained=api.load(\"glove-twitter-25\")\r\n",
        "glove_preTrained=api.load(\"glove-wiki-gigaword-50\")\r\n",
        "\r\n",
        "def get_gloveWord(word):\r\n",
        "  if word[0] in glove_preTrained.wv.vocab:\r\n",
        "    syn = glove_preTrained.most_similar(word[0])\r\n",
        "    syn = [item[0] for item in syn]\r\n",
        "  else:\r\n",
        "    syn = [word[0]]\r\n",
        "  return syn "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LwrI4IviDeP",
        "outputId": "e5a55b1a-5253-40f9-9c60-e5bb47e5ae51"
      },
      "source": [
        "# CHANGES HAS BEEN MADE IN THIS BLOCK WHEN COMPARED TO new.ipynb\r\n",
        "alpha=0.3\r\n",
        "orig_text = re.sub(r'.<br /><br />','. ', text) # to remove break statements\r\n",
        "\r\n",
        "i=1\r\n",
        "replacement_method = \"glove\"\r\n",
        "for j in range(math.trunc(len(ranking)*alpha)):\r\n",
        "    if replacement_method == \"glove\":\r\n",
        "      synlist = get_gloveWord(ranking[j])\r\n",
        "    else: \r\n",
        "      synlist = get_synonyms(ranking[j])\r\n",
        "    '''\r\n",
        "    if len(synlist)-1 < i:\r\n",
        "        index = len(synlist)-1\r\n",
        "    else:\r\n",
        "        index=i\r\n",
        "    '''\r\n",
        "    orig_text = orig_text.replace(ranking[j][0],synlist[0])\r\n",
        "    print('{} ----> {}'.format(ranking[j][0],synlist[0]))\r\n",
        "print(predict(model, orig_text))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "serves ----> serving\n",
            "divided ----> split\n",
            "succession ----> dynastic\n",
            "disappointment ----> frustration\n",
            "II ----> II\n",
            "man ----> woman\n",
            "/>But ----> />But\n",
            "learn ----> understand\n",
            "kind ----> sort\n",
            "film ----> movie\n",
            "else ----> nobody\n",
            "even ----> so\n",
            "anything ----> nothing\n",
            "war ----> occupation\n",
            "transferred ----> subsequently\n",
            "Coast ----> Coast\n",
            "elements ----> element\n",
            "noble ----> descendant\n",
            "displays ----> display\n",
            "sequences ----> sequence\n",
            "We ----> We\n",
            "swimmer ----> medalist\n",
            "Department ----> Department\n",
            "best ----> good\n",
            "The ----> The\n",
            "I ----> I\n",
            "weak ----> weaker\n",
            "visual ----> imagery\n",
            "/>I ----> />I\n",
            "combat ----> force\n",
            "outfit ----> outfits\n",
            "elsewhere ----> throughout\n",
            "Honor ----> Honor\n",
            "It ----> It\n",
            "None ----> None\n",
            "none ----> those\n",
            "wish ----> wishes\n",
            "couple ----> friends\n",
            "A ----> A\n",
            "managed ----> manage\n",
            "knew ----> why\n",
            "/>It ----> />It\n",
            "roles ----> role\n",
            "mostly ----> mainly\n",
            "sea ----> ocean\n",
            "winner ----> wins\n",
            "/><br ----> /><br\n",
            "safety ----> protection\n",
            "In ----> In\n",
            "goes ----> takes\n",
            "S. ----> S.\n",
            "Navy ----> Navy\n",
            "romance ----> romantic\n",
            "works ----> work\n",
            "property ----> estate\n",
            "two ----> three\n",
            "make ----> making\n",
            "situations ----> complicated\n",
            "War ----> War\n",
            "0.7289783358573914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "6vHMQCK3nBl4",
        "outputId": "7cc2fc2f-2064-4df3-c6b7-af18fcd24bc5"
      },
      "source": [
        "text"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I wish I knew what to make of a movie like this. It seems to be divided into two parts -- action sequences and personal dramas ashore. It follows Ashton Kutsher through survival swimmer school, guided by Master Chief Kevin Costner, then to Alaska where a couple of spectacular rescues take place, the last resulting in death.<br /><br />I must say that the scenes on the beach struck me as so stereotypical in so many ways that they should be barnacle encrusted. A typical bar room fight between Navy guys and Coast Guardsmen (\"puddle pirates\"). The experienced old timer Costner who is, as an elderly bar tender tells him, \"married to the Coast Guard.\" The older chief who \"keeps trying to prove to himself that he\\'s still nineteen.\" The neglected ex wife ashore to whom Kostner pays a farewell visit. The seemingly sadistic demands placed on the swimmers by the instructors, all in pursuit of a loftier goal. The gifted young man hobbled by a troubled past.<br /><br />The problem is that we\\'ve seen it all before. If it\\'s Kevin Costner here, it\\'s Clint Eastwood or John Wayne or Lou Gosset Jr. or Vigo Mortenson or Robert DeNiro elsewhere. And the climactic scene has elements drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" None of it is fresh and none of the old stereotyped characters and situations are handled with any originality.<br /><br />It works best as a kind of documentary of what goes on in the swimmer\\'s school and what could happen afterward and even that\\'s a little weak because we don\\'t get much in the way of instruction. It\\'s mostly personal conflict, romance, and tension about washing out.<br /><br />It\\'s a shame because the U. S. Coast Guard is rather a noble outfit, its official mission being \"the safety of lives and property at sea.\" In war time it is transferred to the Navy Department and serves in combat roles. In World War II, the Coast Guard even managed to have a Medal of Honor winner in its ranks.<br /><br />But, again, we don\\'t learn much about that. We don\\'t really learn much about anything. The film devolves into a succession of visual displays and not too much else. A disappointment.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "O93g7LE_iSyy",
        "outputId": "a9c2c2b4-a11f-4611-8055-a18c53aa77b9"
      },
      "source": [
        "orig_text"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I wishes I why what to making of a movie like this. It seems to be split into three parts -- action sequence and personal dramas ashore. It follows Ashton Kutsher through survival medalist school, guided by Master Chief Kevin Costner, then to Alaska where a friends of spectacular rescues take place, the last resulting in death. I must say that the scenes on the beach struck me as so stereotypical in so womany ways that they should be barnacle encrusted. A typical bar room fight between Navy guys and Coast Guardsmen (\"puddle pirates\"). The experienced old timer Costner who is, as an elderly bar tender tells him, \"married to the Coast Guard.\" The older chief who \"keeps trying to prove to himself that he\\'s still nineteen.\" The neglected ex wife ashore to whom Kostner pays a farewell visit. The seemingly sadistic dewomands placed on the medalists by the instructors, all in pursuit of a loftier goal. The gifted young woman hobbled by a troubled past. The problem is that we\\'ve seen it all before. If it\\'s Kevin Costner here, it\\'s Clint Easthreeod or John Wayne or Lou Gosset Jr. or Vigo Mortenson or Robert DeNiro nobodywhere. And the climactic scene has element drawn shamelessly from \"The Perfect Storm\" and \"Dead Calm.\" None of it is fresh and those of the old stereotyped characters and complicated are handled with any originality. It work good as a sort of documentary of what takes on in the medalist\\'s school and what could happen afteroccupationd and so that\\'s a little weaker because we don\\'t get much in the way of instruction. It\\'s mainly personal conflict, rowomance, and tension about washing out. It\\'s a shame because the U. S. Coast Guard is rather a descendant outfits, its official mission being \"the protection of lives and estate at ocean.\" In occupation time it is subsequently to the Navy Department and serving in force role. In World War II, the Coast Guard so womanage to have a Medal of Honor wins in its ranks. But, again, we don\\'t understand much about that. We don\\'t really understand much about nothing. The movie devolves into a dynastic of imagery display and not too much nobody. A frustration.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZuu_pnOiy3x",
        "outputId": "d6bdcdaf-7dda-460c-feb6-87fa0ea2e322"
      },
      "source": [
        "print(predict(model, text))\r\n",
        "predict(model, orig_text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12099010497331619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7289783358573914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPeKI8Y_i0Yi"
      },
      "source": [
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\r\n",
        "t1 = sbert_model.encode(text)\r\n",
        "t2 = sbert_model.encode(orig_text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}